{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../../')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from src.data.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/scratch/bbug/ayang1/raw_data/lucas/s1_lucas_2018'\n",
    "save_path = '/scratch/bbug/ayang1/datasets/lucas_dataset_ieitptnl'\n",
    "\n",
    "# Collect ee generated time series data\n",
    "ds = [\n",
    "    'S1_point_10days_10m_1Jan-31Dec_Ireland_ratio-db.csv',\n",
    "    'S1_point_10days_10m_1Jan-31Dec_Italy_ratio-db.csv',\n",
    "    'S1_point_10days_10m_1Jan-31Dec_Netherlands_ratio-db.csv',\n",
    "    'S1_point_10days_10m_1Jan-31Dec_Portugal_ratio-db.csv'      \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2280934/4214113462.py:2: DtypeWarning: Columns (34,39,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  labels = pd.read_csv('/scratch/bbug/ayang1/raw_data/lucas/lucas_2018/copernicus_filtered/lucas_2018_filtered.csv')\n"
     ]
    }
   ],
   "source": [
    "# Lucas labels \n",
    "labels = pd.read_csv('/scratch/bbug/ayang1/raw_data/lucas/lucas_2018/copernicus_filtered/lucas_2018_filtered.csv')\n",
    "\n",
    "dfs = []\n",
    "for path in ds:\n",
    "    dfs.append(pd.read_csv(os.path.join(data_root, path)))\n",
    "\n",
    "data= pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files\n",
      "Creating dataset of size 239980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239980/239980 [01:09<00:00, 3440.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add labels to signals based on point id\n",
    "crop_data = add_lucas_labels(data, labels)\n",
    "crop_data.drop('system:index', axis=1, inplace=True)\n",
    "crop_data = crop_data.loc[crop_data['LABEL']!='NOT_CROP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data.to_csv(os.path.join(save_path, 'IE_IT_PT_NL_s1.csv'))\n",
    "crop_data = pd.read_csv(os.path.join(save_path, 'IE_IT_PT_NL_s1.csv')).drop('Unnamed: 0', axis=1)\n",
    "crop_data = crop_data.drop(['POINT_ID', '.geo'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped classes: ['B14', 'B17', 'B18', 'B19', 'B22', 'B23', 'B31', 'B32', 'B33', 'B35', 'B36', 'B37', 'B42', 'B43', 'B44', 'B51', 'B71', 'B74', 'B75', 'B81', 'B82', 'B83']\n"
     ]
    }
   ],
   "source": [
    "# Filter out classes with less than 1000 samples\n",
    "counts = np.unique(crop_data['LABEL'], return_counts=True)\n",
    "to_drop = [counts[0][i] for i in range(len(counts[0])) if counts[1][i] < 1000]\n",
    "crop_data = crop_data.loc[~crop_data['LABEL'].isin(to_drop)]\n",
    "\n",
    "print('Dropped classes:', to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets as npy files\n",
    "arr = crop_data.to_numpy()\n",
    "vhvv = arr[:, np.newaxis, 0:36]\n",
    "vh = arr[:, np.newaxis, 36:72]\n",
    "vv = arr[:, np.newaxis, 72:108]\n",
    "labels = arr[:, 108]\n",
    "\n",
    "data = np.concatenate([vhvv, vh, vv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signals, test_signals, train_labels, test_labels = train_test_split(data, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(save_path, 'train_signals.npy'), train_signals)\n",
    "np.save(os.path.join(save_path, 'test_signals.npy'), test_signals)\n",
    "np.save(os.path.join(save_path, 'train_labels.npy'), train_labels)\n",
    "np.save(os.path.join(save_path, 'test_labels.npy'), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = train_signals[15, :, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
